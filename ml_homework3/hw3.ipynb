{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "iAPl-9kU0ZGR",
    "outputId": "d295f85b-c269-4d75-b458-e4e63f37d5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073750016 bytes == 0x5df0c000 @  0x7fc185d5f2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 1.9MB/s \n",
      "\u001b[?25hInstalling collected packages: pillow, torchvision\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.3.0 torchvision-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3858
    },
    "colab_type": "code",
    "id": "0baK4zB_2uZz",
    "outputId": "434ed86f-4ba5-48a0-8989-340260f17bcf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_kernel(model):\n",
    "    model_weights = model.state_dict()\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(model_weights['conv1.weight']):\n",
    "    #print(filt[0, :, :])\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt[0, :, :], cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_kernel_output(model,images):\n",
    "    fig1 = plt.figure()\n",
    "    plt.figure(figsize=(1,1))\n",
    "    \n",
    "    img_normalized = (images[0] - images[0].min()) / (images[0].max() - images[0].min())\n",
    "    plt.imshow(img_normalized.numpy().transpose(1,2,0))\n",
    "    plt.show()\n",
    "    output = model.conv1(images)\n",
    "    layer_1 = output[0, :, :, :]\n",
    "    layer_1 = layer_1.data\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(layer_1):\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def test_accuracy(net, dataloader):\n",
    "  ########TESTING PHASE###########\n",
    "  \n",
    "    #check accuracy on whole test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval() #important for deactivating dropout and correctly use batchnorm accumulated statistics\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the network on the test set: %d %%' % (\n",
    "    accuracy))\n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "n_classes = 100 \n",
    "# function to define an old style fully connected network (multilayer perceptrons)\n",
    "class old_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(old_nn, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, n_classes) #last FC for classification \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "      \n",
    "      \n",
    "#function to define the convolutional network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #conv2d first parameter is the number of kernels at input (you get it from the output value of the previous layer)\n",
    "        #conv2d second parameter is the number of kernels you wanna have in your convolution, so it will be the n. of kernels at output.\n",
    "        #conv2d third, fourth and fifth parameters are, as you can read, kernel_size, stride and zero padding :)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_final = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 4096)\n",
    "        self.fc2 = nn.Linear(4096, n_classes) #last FC for classification \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.pool(self.conv_final(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #hint: dropout goes here!\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3858
    },
    "colab_type": "code",
    "id": "0baK4zB_2uZz",
    "outputId": "434ed86f-4ba5-48a0-8989-340260f17bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "      ####RUNNING CODE FROM HERE:\n",
    "      \n",
    "#transform are heavily used to do simple and complex transformation and data augmentation\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=0,drop_last=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
    "                                         shuffle=False, num_workers=0,drop_last=True)\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "###OPTIONAL:\n",
    "# show images just to understand what is inside the dataset ;)\n",
    "#images, labels = dataiter.next()\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "####\n",
    "\n",
    "\n",
    "#create the old style NN network\n",
    "#net = old_nn()\n",
    "###\n",
    "\n",
    "net = CNN()\n",
    "####\n",
    "#for Residual Network:\n",
    "#net = models.resnet18(pretrained=True)\n",
    "#net.fc = nn.Linear(512, n_classes) #changing the fully connected layer of the already allocated network\n",
    "####\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting kernels of conv1 layer:####\")\n",
    "#plot_kernel(net)\n",
    "####\n",
    "\n",
    "\n",
    "net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() #it already does softmax computation for use!\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) #better convergency w.r.t simple SGD :)\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting output of conv1 layer:#####\")\n",
    "#plot_kernel_output(net,images)  \n",
    "###\n",
    "print('Data ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3858
    },
    "colab_type": "code",
    "id": "0baK4zB_2uZz",
    "outputId": "434ed86f-4ba5-48a0-8989-340260f17bcf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   195] loss: 4.226\n",
      "Accuracy of the network on the test set: 10 %\n",
      "[2,   195] loss: 3.806\n",
      "Accuracy of the network on the test set: 14 %\n",
      "[3,   195] loss: 3.619\n",
      "Accuracy of the network on the test set: 16 %\n",
      "[4,   195] loss: 3.480\n",
      "Accuracy of the network on the test set: 18 %\n",
      "[5,   195] loss: 3.369\n",
      "Accuracy of the network on the test set: 20 %\n",
      "[6,   195] loss: 3.271\n",
      "Accuracy of the network on the test set: 21 %\n",
      "[7,   195] loss: 3.186\n",
      "Accuracy of the network on the test set: 23 %\n",
      "[8,   195] loss: 3.109\n",
      "Accuracy of the network on the test set: 23 %\n",
      "[9,   195] loss: 3.037\n",
      "Accuracy of the network on the test set: 24 %\n",
      "[10,   195] loss: 2.967\n",
      "Accuracy of the network on the test set: 25 %\n",
      "[11,   195] loss: 2.900\n",
      "Accuracy of the network on the test set: 25 %\n",
      "[12,   195] loss: 2.840\n",
      "Accuracy of the network on the test set: 26 %\n",
      "[13,   195] loss: 2.769\n",
      "Accuracy of the network on the test set: 27 %\n",
      "[14,   195] loss: 2.707\n",
      "Accuracy of the network on the test set: 27 %\n",
      "[15,   195] loss: 2.643\n",
      "Accuracy of the network on the test set: 28 %\n",
      "[16,   195] loss: 2.571\n",
      "Accuracy of the network on the test set: 28 %\n",
      "[17,   195] loss: 2.501\n",
      "Accuracy of the network on the test set: 28 %\n",
      "[18,   195] loss: 2.431\n",
      "Accuracy of the network on the test set: 28 %\n",
      "[19,   195] loss: 2.366\n",
      "Accuracy of the network on the test set: 29 %\n",
      "[20,   195] loss: 2.286\n",
      "Accuracy of the network on the test set: 29 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "########TRAINING PHASE###########\n",
    "#1/6\n",
    "n_loss_print = len(trainloader)  #print every epoch, use smaller numbers if you wanna print loss more often!\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    net.train() #important for activating dropout and correctly train batchnorm\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and cast them into cuda wrapper\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_loss_print == (n_loss_print -1):    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / n_loss_print))\n",
    "            running_loss = 0.0\n",
    "    test_accuracy(net,testloader)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########TRAINING PHASE###########\n",
    "#2/6\n",
    "n_loss_print = len(trainloader)  #print every epoch, use smaller numbers if you wanna print loss more often!\n",
    "n_epochs = 20\n",
    "stats = np.empty((n_epochs,2))\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    net.train() #important for activating dropout and correctly train batchnorm\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and cast them into cuda wrapper\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_loss_print == (n_loss_print -1):    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / n_loss_print))\n",
    "            stats[epoch][1] = running_loss / n_loss_print\n",
    "            running_loss = 0.0\n",
    "    stats[epoch][0] = test_accuracy(net,testloader)\n",
    "print('Finished Training')\n",
    "param_range = np.arange(n_epochs+1)\n",
    "plt.ylim(0.0, 100.0)\n",
    "plt.semilogx(param_range, stats[:,0], label='Accuracy', lw=lw)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (21,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1ec55242cc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msemilogx\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2798\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msemilogx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m \u001b[1;31m# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36msemilogx\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1790\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1602\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1604\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1605\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 231\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (21,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = np.empty(n_epochs)\n",
    "print(stats.shape)\n",
    "stats = np.empty((n_epochs,2))\n",
    "param_range = np.arange(n_epochs+1)\n",
    "lw = 1\n",
    "plt.ylim(0.0, 100.0)\n",
    "plt.semilogx(param_range, stats[:,0], label='Accuracy', lw=lw)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
